{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71b2abec-7034-4998-b107-dfe19711eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "#\n",
    "#Connection string for sqlalchemy\n",
    "connection_string = \"Driver={ODBC Driver 17 for SQL Server};Server=MY_GENIE\\SQLEXPRESS;Database=QN 1 OLTP;Trusted_Connection=yes;\"\n",
    "#connection_string =\"Driver={ODBC Driver 17 for SQL Server};Server=stwssbsql01.ad.okstate.edu;Database=MYStoreDW;Trusted_Connection=yes;\"\n",
    "connection_string = urllib.parse.quote_plus(connection_string)\n",
    "connection_string = \"mssql+pyodbc:///?odbc_connect=%s\" % connection_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93645e1-c731-483a-9848-b49b1967463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Day_of_Week', 'Year'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('date.csv', parse_dates=['Date'])\n",
    "print(df.columns)  # This will print the list of columns as read from the CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82526c-216d-40e5-84b6-32310fa57edd",
   "metadata": {},
   "source": [
    "## Dates csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7fd11c5-2c36-4888-9045-2ad96ca23d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phani\\AppData\\Local\\Temp\\ipykernel_13504\\76810435.py:8: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "class DateData(Base):\n",
    "    __tablename__ = 'Dates'\n",
    "    Date = Column(Date, primary_key=True)\n",
    "    Day_of_Week = Column(String)\n",
    "    Year = Column(Integer)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path, parse_dates=['Date'])\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing Date csv into Dates table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    # Check for duplicates\n",
    "    duplicates = df[df.duplicated(['Date'], keep=False)]  # Checking duplicates based on 'Date'\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 1 : Checking for duplicates. \\n\")\n",
    "        if not duplicates.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - DATES : Duplicates found in row no. {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - DATES : No duplicates found.\\n\")\n",
    "\n",
    "    # Removing duplicates\n",
    "    df.drop_duplicates(subset=['Date'], inplace=True)\n",
    "    \n",
    "    rows_to_drop = []\n",
    "    flag2=0\n",
    "    for index, row in df.iterrows():\n",
    "        if not isinstance(row['Year'], int):\n",
    "            flag2=1\n",
    "            with open('task1.txt', 'a') as f:\n",
    "                f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "                out_str = f\"Row {index + 1} in Date table {whfile} has a non-numeric Year and will be dropped\\n\"\n",
    "                f.write(out_str)\n",
    "                rows_to_drop.append(index)\n",
    "    if flag2==0:\n",
    "        with open('task1.txt', 'a') as f:\n",
    "            f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "            f.write(\"Table - DATES : All the entries are of correct datatype.\\n\")\n",
    "            #print(f\"Row {index + 1} in Date table {whfile} has a non-numeric Year and will be dropped\")\n",
    "            \n",
    "    df.drop(rows_to_drop, inplace=True)\n",
    "            \n",
    "    rows_to_drop1 = []\n",
    "    flag3=0\n",
    "    for index, row in df.iterrows():\n",
    "        if  row['Year']<0:\n",
    "            flag3=1\n",
    "            with open('task1.txt', 'a') as f:\n",
    "                f.write(\"Validation check 3 : Checking for Year range. \\n\")\n",
    "                out_str = f\"Row {index + 1} in Date table {whfile} has a negative Year (invalid) and will be dropped\\n\"\n",
    "                f.write(out_str)\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                rows_to_drop1.append(index)\n",
    "    if flag3==0:\n",
    "        with open('task1.txt', 'a') as f:\n",
    "            f.write(\"Validation check 3 : Checking for Year range. \\n\")\n",
    "            f.write(\"Table - DATES : Year column entries are in correct range (greater than 0)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            #print(f\"Row {index + 1} in Date table {whfile} has a positive Year and will be dropped\")\n",
    "            \n",
    "\n",
    "    df.drop(rows_to_drop1, inplace=True)\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = DateData(Date=row['Date'], Day_of_Week=row['Day_of_Week'], Year=row['Year'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - DATES : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'date.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc2906-2d41-49e3-b43a-724b04941238",
   "metadata": {},
   "source": [
    "## Location csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c51e4d83-924f-4a6e-8f92-e4dbe0aa02ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phani\\AppData\\Local\\Temp\\ipykernel_13504\\2560385124.py:8: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class DateData(Base):\n",
    "    __tablename__ = 'Location'\n",
    "    Latitude = Column(Float,primary_key=True)  # Float is now correctly imported and used\n",
    "    Longitude = Column(Float,primary_key=True)  # Float is now correctly imported and used\n",
    "    Location_Easting_OSGR = Column(String)  \n",
    "    Location_Northing_OSGR = Column(String)  \n",
    "    LSOA_of_Accident_Location = Column(String)  \n",
    "    Police_Force = Column(String)  \n",
    "    Urban_or_Rural_Area = Column(String)  \n",
    "    InScotland = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing location csv into Location table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    # Check for duplicates\n",
    "    duplicates = df[df.duplicated(['Latitude','Longitude'], keep=False)]  # Checking duplicates based on 'Date'\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 1 : Checking for duplicates. \\n\")\n",
    "        if not duplicates.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - Location : Duplicates found in row no. {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - Location : No duplicates found.\\n\")\n",
    "\n",
    "    # Removing duplicates\n",
    "    df.drop_duplicates(subset=['Latitude','Longitude'], inplace=True)\n",
    "    \n",
    "    rows_to_drop = []\n",
    "    flag2=0\n",
    "    for index, row in df.iterrows():\n",
    "        if not isinstance(row['Latitude'], int) & isinstance(row['Longitude'], int):\n",
    "            flag2=1\n",
    "            with open('task1.txt', 'a') as f:\n",
    "                f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "                out_str = f\"Row {index + 1} in Date table  has a non-numeric Latitude& Longitude and will be dropped\\n\"\n",
    "                f.write(out_str)\n",
    "                rows_to_drop.append(index)\n",
    "    if flag2==0:\n",
    "        with open('task1.txt', 'a') as f:\n",
    "            f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "            f.write(\"Table - Location : All the entries are of correct datatype.\\n\")\n",
    "            #print(f\"Row {index + 1} in Date table {whfile} has a non-numeric Year and will be dropped\")\n",
    "            \n",
    "    df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "    missing_latitudes = df[(df['Latitude'].isnull())|(df['Longitude'].isnull())]\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 3 : Checking for missing entries. \\n\")\n",
    "        if not missing_latitudes.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - Location : Missing entry in Primary key at row no: {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - Location : No missing entries.\\n\")\n",
    "    #df = df.dropna(subset=['Latitude','Longitude'])\n",
    "\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = DateData(Latitude=row['Latitude'], Longitude=row['Longitude'], Location_Easting_OSGR=row['Location_Easting_OSGR'],\n",
    "                              Location_Northing_OSGR=row['Location_Northing_OSGR'], LSOA_of_Accident_Location=row['LSOA_of_Accident_Location'], \n",
    "                              Police_Force=row['Police_Force'],Urban_or_Rural_Area=row['Urban_or_Rural_Area'], Day_of_Week=row['InScotland'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Location : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'location.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471b2305-040f-49a3-bed8-6a57968a4910",
   "metadata": {},
   "source": [
    "## Ped human control CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5597e938-edf2-4b8d-88b0-00488b5c0ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class LocationData(Base):\n",
    "    __tablename__ = 'Ped human control'\n",
    "    Pedestrian_Crossing_Human_Control = Column(Integer,primary_key=True)  # Float is now correctly imported and used\n",
    "    Meaning = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing Ped human control csv into Pedestrian_Human_Control table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = LocationData(Pedestrian_Crossing_Human_Control=row['Pedestrian_Crossing_Human_Control'],Meaning=row['Meaning'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Pedestrian_Crossing_Human_Control : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'Ped human control.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0135bf-3c8a-4747-9bcc-2550b029ace2",
   "metadata": {},
   "source": [
    "## Ped Physical faciltiies CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf7fe8-fb5c-412d-9f4b-ccaf86d833d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class LocationData(Base):\n",
    "    __tablename__ = 'Pedestrian_Physical_Facilities'\n",
    "    Pedestrian_Crossing_Physical_Facilities = Column(Integer,primary_key=True)  # Float is now correctly imported and used\n",
    "    Meaning = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing Ped Physical faciltiies csv into Pedestrian_Physical_Facilities table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = LocationData(Pedestrian_Crossing_Human_Control=row['Pedestrian_Crossing_Physical_Facilities'],Meaning=row['Meaning'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Pedestrian_Crossing_Physical_Facilities : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'Ped Physical faciltiies.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0713c8a-9960-4ace-b457-4dc0cbe72d48",
   "metadata": {},
   "source": [
    "## Police attended CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a779a73-29da-4921-bb57-627e642d09b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class LocationData(Base):\n",
    "    __tablename__ = 'Police_Attendance'\n",
    "    Did_Police_Officer_Attend_Scene_of_Accident = Column(Integer,primary_key=True)  # Float is now correctly imported and used\n",
    "    Meaning = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing Police attended csv into Police_Attendance table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = LocationData(Did_Police_Officer_Attend_Scene_of_Accident=row['Did_Police_Officer_Attend_Scene_of_Accident'],Meaning=row['Meaning'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Police_Attendance : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'Police attended.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f9e80-37be-457c-a20d-a487d58a5da3",
   "metadata": {},
   "source": [
    "## Driver IMD Decile CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c0445-17a6-4642-bb04-1b9d657db2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class LocationData(Base):\n",
    "    __tablename__ = 'IMD_Decile'\n",
    "    Driver_IMD_Decile = Column(Integer,primary_key=True)  # Float is now correctly imported and used\n",
    "    Meaning = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing Driver IMD Decile csv into IMD_Decile table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = LocationData(Driver_IMD_Decile=row['Driver_IMD_Decile'],Meaning=row['Meaning'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - IMD_Decile : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'Driver IMD Decile.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b366eae-a49e-4b99-9b24-03dac5101397",
   "metadata": {},
   "source": [
    "## Restricted lane CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5581da-0de0-449c-ae06-a53fa148bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class LocationData(Base):\n",
    "    __tablename__ = 'Restricted_Lane'\n",
    "    Vehicle_Location_Restricted_Lane = Column(Integer,primary_key=True)  # Float is now correctly imported and used\n",
    "    Meaning = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing Restricted lane csv into Restricted_Lane table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = LocationData(Vehicle_Location_Restricted_Lane=row['Vehicle_Location_Restricted_Lane'],Meaning=row['Meaning'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Restricted_Lane : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'Restricted lane.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69ebf62-93c4-4504-a88d-718475702372",
   "metadata": {},
   "source": [
    "## accident_location CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2fabf-d79e-45ba-b969-c5f7b2f61b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Date\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "class DateData(Base):\n",
    "    __tablename__ = 'Accident_Location'\n",
    "    Accident_Index = Column(String, primary_key=True)\n",
    "    Junction_Location = Column(String)\n",
    "    Year = Column(Integer)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing accident_location csv into Accident_Location table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    # Check for duplicates\n",
    "    duplicates = df[df.duplicated(['Accident_Index'], keep=False)]  # Checking duplicates based on 'Date'\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 1 : Checking for duplicates. \\n\")\n",
    "        if not duplicates.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - Accident_Location : Duplicates found in row no. {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - Accident_Location : No duplicates found.\\n\")\n",
    "\n",
    "    # Removing duplicates\n",
    "    df.drop_duplicates(subset=['Accident_Index'], inplace=True)\n",
    "    \n",
    "    rows_to_drop = []\n",
    "    flag2=0\n",
    "    for index, row in df.iterrows():\n",
    "        if not isinstance(row['Year'], int):\n",
    "            flag2=1\n",
    "            with open('task1.txt', 'a') as f:\n",
    "                f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "                out_str = f\"Row {index + 1} in Accident_Location table {whfile} has a non-numeric Year and will be dropped\\n\"\n",
    "                f.write(out_str)\n",
    "                rows_to_drop.append(index)\n",
    "    if flag2==0:\n",
    "        with open('task1.txt', 'a') as f:\n",
    "            f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "            f.write(\"Table - Accident_Location : All the entries are of correct datatype.\\n\")\n",
    "            #print(f\"Row {index + 1} in Date table {whfile} has a non-numeric Year and will be dropped\")\n",
    "            \n",
    "    df.drop(rows_to_drop, inplace=True)\n",
    "            \n",
    "    rows_to_drop1 = []\n",
    "    flag3=0\n",
    "    for index, row in df.iterrows():\n",
    "        if  row['Year']<0:\n",
    "            flag3=1\n",
    "            with open('task1.txt', 'a') as f:\n",
    "                f.write(\"Validation check 3 : Checking for Year range. \\n\")\n",
    "                out_str = f\"Row {index + 1} in Accident_Location table {whfile} has a negative Year (invalid) and will be dropped\\n\"\n",
    "                f.write(out_str)\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                rows_to_drop1.append(index)\n",
    "    if flag3==0:\n",
    "        with open('task1.txt', 'a') as f:\n",
    "            f.write(\"Validation check 3 : Checking for Year range. \\n\")\n",
    "            f.write(\"Table - Accident_Location : Year column entries are in correct range (greater than 0)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "            #print(f\"Row {index + 1} in Date table {whfile} has a positive Year and will be dropped\")\n",
    "            \n",
    "\n",
    "    df.drop(rows_to_drop1, inplace=True)\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = DateData(Accident_Index=row['Accident_Index'],Junction_Location=row['Junction_Location'], Year=row['Year'])\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Accident_Location : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'accident_location.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcda9b9-e39a-4a9f-a1f8-e4faa2bf1bc6",
   "metadata": {},
   "source": [
    "## accidents CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c050bb-9075-4475-b6ec-f97c1316de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class AccidentData(Base):\n",
    "    __tablename__ = 'Accidents'\n",
    "    Accident_Index = Column(String, primary_key=True)\n",
    "    First_Road_Class = Column(String)\n",
    "    First_Road_Number = Column(Integer)\n",
    "    Second_Road_Class = Column(String)\n",
    "    Second_Road_Number = Column(Integer)\n",
    "    Accident_Severity = Column(String)\n",
    "    Carriageway_Hazards = Column(String)\n",
    "    Date = Column(Date)\n",
    "    Did_Police_Officer_Attend_Scene_of_Accident = Column(Integer)\n",
    "    Junction_Control = Column(String)\n",
    "    Junction_Detail = Column(String)\n",
    "    Latitude = Column(Float)\n",
    "    Longitude = Column(Float)\n",
    "    Light_Conditions = Column(String)\n",
    "    Local_District_Authority = Column(String)\n",
    "    Local_Highway_Authority = Column(String)\n",
    "    Number_of_Casualities = Column(Integer)\n",
    "    Number_of_Vehicles = Column(Integer)\n",
    "    Pedestrian_Crossing_Human_Control = Column(Integer)\n",
    "    Pedestrian_Crossing_Physical_Facilities = Column(Integer)\n",
    "    Road_Surface_Conditions = Column(String)\n",
    "    Road_Type = Column(String)\n",
    "    Special_Conditions_at_Site = Column(String)\n",
    "    Speed_limit = Column(Integer)\n",
    "    Time = Column(Time)\n",
    "    Weather_Conditions = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing accidents csv into Accidents table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    # Check for duplicates\n",
    "    duplicates = df[df.duplicated(['Accident_Index'], keep=False)]  # Checking duplicates based on 'Date'\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 1 : Checking for duplicates. \\n\")\n",
    "        if not duplicates.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - Accidents : Duplicates found in row no. {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - Accidents : No duplicates found.\\n\")\n",
    "\n",
    "    # Removing duplicates\n",
    "    df.drop_duplicates(subset=['Accident_Index'], inplace=True)\n",
    "    \n",
    "    rows_to_drop = []\n",
    "    flag2=0\n",
    "    for index, row in df.iterrows():\n",
    "        if not isinstance(row['Latitude'], int) & isinstance(row['Longitude'], int):\n",
    "            flag2=1\n",
    "            with open('task1.txt', 'a') as f:\n",
    "                f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "                out_str = f\"Row {index + 1} in Accidents table  has a non-numeric Latitude& Longitude and will be dropped\\n\"\n",
    "                f.write(out_str)\n",
    "                rows_to_drop.append(index)\n",
    "    if flag2==0:\n",
    "        with open('task1.txt', 'a') as f:\n",
    "            f.write(\"Validation check 2 : Checking for Datatypes. \\n\")\n",
    "            f.write(\"Table - Accidents : All the entries are of correct datatype.\\n\")\n",
    "            #print(f\"Row {index + 1} in Date table {whfile} has a non-numeric Year and will be dropped\")\n",
    "            \n",
    "    df.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "    missing_entry = df[(df['Accident_Index'].isnull())]\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 3 : Checking for missing entries. \\n\")\n",
    "        if not missing_entry.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - Accidents : Missing entry in Primary key at row no: {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - Accidents : No missing entries.\\n\")\n",
    "    #df = df.dropna(subset=['Latitude','Longitude'])\n",
    "\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = AccidentData(Accident_Index=row['Accident_Index'],First_Road_Class=row['First_Road_Class'],First_Road_Number=row['First_Road_Number'],\n",
    "        Second_Road_Class=row['Second_Road_Class'],Second_Road_Number=row['Second_Road_Number'],Accident_Severity=row['Accident_Severity'],\n",
    "        Carriageway_Hazards=row['Carriageway_Hazards'],Date=row['Date'],Did_Police_Officer_Attend_Scene_of_Accident=row['Did_Police_Officer_Attend_Scene_of_Accident'],\n",
    "        Junction_Control=row['Junction_Control'],Junction_Detail=row['Junction_Detail'],Latitude=row['Latitude'],Longitude=row['Longitude'],\n",
    "        Light_Conditions=row['Light_Conditions'],Local_District_Authority=row['Local_District_Authority'],Local_Highway_Authority=row['Local_Highway_Authority'],\n",
    "        Number_of_Casualities=row['Number_of_Casualities'],Number_of_Vehicles=row['Number_of_Vehicles'],Pedestrian_Crossing_Human_Control=row['Pedestrian_Crossing_Human_Control'],\n",
    "        Pedestrian_Crossing_Physical_Facilities=row['Pedestrian_Crossing_Physical_Facilities'],Road_Surface_Conditions=row['Road_Surface_Conditions'],\n",
    "        Road_Type=row['Road_Type'],Special_Conditions_at_Site=row['Special_Conditions_at_Site'],Speed_limit=row['Speed_limit'],Time=row['Time'],\n",
    "        Weather_Conditions=row['Weather_Conditions'])\n",
    "\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Accidents : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'accidents.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ef952-6040-4815-a776-0a7432ce854d",
   "metadata": {},
   "source": [
    "## vehicles CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdbfe84-332b-4922-8cb5-c4c4c52cb04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date  # Include Float here\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "\n",
    "# Define ORM class\n",
    "Base = declarative_base()\n",
    "\n",
    "class AccidentData(Base):\n",
    "    __tablename__ = 'Vehicle'\n",
    "    Accident_Index = Column(String, primary_key=True)\n",
    "    Age_Band_of_Driver = Column(String)\n",
    "    Age_of_Vehicle = Column(Integer)\n",
    "    Driver_Home_Area_Type = Column(String)\n",
    "    Driver_IMD_Decile = Column(Integer)\n",
    "    Engine_Capacity_CC = Column(Integer)\n",
    "    Hit_Object_in_Carriageway = Column(String)\n",
    "    Hit_Object_off_Carriageway = Column(String)\n",
    "    Journey_Purpose_of_Driver = Column(String)\n",
    "    Make = Column(String)\n",
    "    Model = Column(String)\n",
    "    Propulsion_Code = Column(String)\n",
    "    Sex_of_Driver = Column(String)\n",
    "    Skidding_and_Overturning = Column(String)\n",
    "    Towing_and_Articulation = Column(String)\n",
    "    Vehicle_Leaving_Carriageway = Column(String)\n",
    "    Vehicle_Location_Restricted_Lane = Column(Integer)\n",
    "    Vehicle_Manoeuvre = Column(String)\n",
    "    Vehicle_Reference = Column(Integer, primary_key=True)\n",
    "    Vehicle_Type = Column(String)\n",
    "    Was_Vehicle_Left_Hand_Drive = Column(String)\n",
    "    X1st_Point_of_Impact = Column(String)\n",
    "\n",
    "def process_csv_data(connection_string, csv_file_path):\n",
    "    # Engine to read CSV data\n",
    "    engine_db = create_engine(connection_string)\n",
    "    \n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Importing vehicles csv into Vehicle table in Database ACCIDENTS\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "    # Check for duplicates\n",
    "    duplicates = df[df.duplicated(['Accident_Index','Vehicle_Reference'], keep=False)]  # Checking duplicates based on 'Date'\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 1 : Checking for duplicates. \\n\")\n",
    "        if not duplicates.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - Vehicle : Duplicates found in row no. {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - Vehicle : No duplicates found.\\n\")\n",
    "\n",
    "    # Removing duplicates\n",
    "    df.drop_duplicates(subset=['Accident_Index','Vehicle_Reference'], inplace=True)\n",
    "    \n",
    "    rows_to_drop1 = []\n",
    "    flag3=0\n",
    "    for index, row in df.iterrows():\n",
    "        if  row['Age_of_Vehicle']<0:\n",
    "            flag3=1\n",
    "            with open('task1.txt', 'a') as f:\n",
    "                f.write(\"Validation check 2 : Checking for Age_of_Vehicle range. \\n\")\n",
    "                out_str = f\"Row {index + 1} in Vehicle table  has a negative Age_of_Vehicle (invalid) and will be dropped\\n\"\n",
    "                f.write(out_str)\n",
    "                f.write(\"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "                rows_to_drop1.append(index)\n",
    "    if flag3==0:\n",
    "        with open('task1.txt', 'a') as f:\n",
    "            f.write(\"Validation check 2 : Checking for Age_of_Vehicle range. \\n\")\n",
    "            f.write(\"Table - Vehicle : Age_of_Vehicle column entries are in correct range (greater than 0)\\n\")\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    missing_entry = df[(df['Accident_Index','Vehicle_Reference'].isnull())]\n",
    "    flagd=0\n",
    "    # Logging duplicates or lack thereof\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        f.write(\"Validation check 3 : Checking for missing entries. \\n\")\n",
    "        if not missing_entry.empty:\n",
    "            flagd=1\n",
    "            for index in duplicates.index:\n",
    "                f.write(f\" Table - Vehicle : Missing entry in Primary key at row no: {index + 1}\\n\")\n",
    "        if flagd==0:\n",
    "            f.write(\"Table - Vehicle : No missing entries.\\n\")\n",
    "    #df = df.dropna(subset=['Latitude','Longitude'])\n",
    "\n",
    "\n",
    "    # Create engine for target database and create table if not exists\n",
    "    engine_dw = create_engine(connection_string)\n",
    "    Base.metadata.create_all(engine_dw)\n",
    "\n",
    "    # Setup session\n",
    "    Session = sessionmaker(bind=engine_dw)\n",
    "    session = Session()\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in df.iterrows():\n",
    "        # Create new record and add to the session\n",
    "        new_record = AccidentData(Accident_Index=row['Accident_Index'],Age_Band_of_Driver=row['Age_Band_of_Driver'],Age_of_Vehicle=row['Age_of_Vehicle'],\n",
    "        Driver_Home_Area_Type=row['Driver_Home_Area_Type'],Driver_IMD_Decile=row['Driver_IMD_Decile'],Engine_Capacity_CC=row['Engine_Capacity_CC'],\n",
    "        Hit_Object_in_Carriageway=row['Hit_Object_in_Carriageway'],Hit_Object_off_Carriageway=row['Hit_Object_off_Carriageway'],Journey_Purpose_of_Driver=row['Journey_Purpose_of_Driver'],\n",
    "        Make=row['Make'],Model=row['Model'],Propulsion_Code=row['Propulsion_Code'],Sex_of_Driver=row['Sex_of_Driver'],Skidding_and_Overturning=row['Skidding_and_Overturning'],\n",
    "        Towing_and_Articulation=row['Towing_and_Articulation'],Vehicle_Leaving_Carriageway=row['Vehicle_Leaving_Carriageway'],Vehicle_Location_Restricted_Lane=row['Vehicle_Location_Restricted_Lane'],\n",
    "        Vehicle_Manoeuvre=row['Vehicle_Manoeuvre'],Vehicle_Reference=row['Vehicle_Reference'],Vehicle_Type=row['Vehicle_Type'],\n",
    "        Was_Vehicle_Left_Hand_Drive=row['Was_Vehicle_Left_Hand_Drive'],X1st_Point_of_Impact=row['X1st_Point_of_Impact'])\n",
    "\n",
    "\n",
    "        session.add(new_record)\n",
    "        counter += 1\n",
    "\n",
    "    session.commit()\n",
    "    session.close()\n",
    "\n",
    "    # Logging the number of rows entered\n",
    "    with open('task1.txt', 'a') as f:\n",
    "        dt = datetime.datetime.now()\n",
    "        dt_str = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"TimeStamp: {dt_str} --- Number of new records loaded IN Table - Vehicle : {counter}\\n\")\n",
    "        f.write(\"-----------------------------------------------------------------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "process_csv_data(connection_string,'vehicles.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
